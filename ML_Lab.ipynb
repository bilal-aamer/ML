{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bcf3a46",
   "metadata": {},
   "source": [
    "## Problem Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8d677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2933b70b",
   "metadata": {},
   "source": [
    "## 1. K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2fa7e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classification accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # Compute distances between x and all examples in the training set\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        # Sort by distance and return indices of the first k neighbors\n",
    "        k_idx = np.argsort(distances)[: self.k]\n",
    "        # Extract the labels of the k nearest neighbor training samples\n",
    "        k_neighbor_labels = [self.y_train[i] for i in k_idx]\n",
    "        # return the most common class label\n",
    "        most_common = Counter(k_neighbor_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "\n",
    "\n",
    "# Imports\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1234\n",
    ")\n",
    "\n",
    "k = 3\n",
    "clf = KNN(k=k)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"KNN classification accuracy\", accuracy(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036cd6ca",
   "metadata": {},
   "source": [
    "## 2. K - Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdecc42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2)\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "\n",
    "class KMeans:\n",
    "    def __init__(self, K=5, max_iters=100, plot_steps=False):\n",
    "        self.K = K\n",
    "        self.max_iters = max_iters\n",
    "        self.plot_steps = plot_steps\n",
    "\n",
    "        # list of sample indices for each cluster\n",
    "        self.clusters = [[] for _ in range(self.K)]\n",
    "        # the centers (mean feature vector) for each cluster\n",
    "        self.centroids = []\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.X = X\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "\n",
    "        # initialize\n",
    "        random_sample_idxs = np.random.choice(self.n_samples, self.K, replace=False)\n",
    "        self.centroids = [self.X[idx] for idx in random_sample_idxs]\n",
    "\n",
    "        # Optimize clusters\n",
    "        for _ in range(self.max_iters):\n",
    "            # Assign samples to closest centroids (create clusters)\n",
    "            self.clusters = self._create_clusters(self.centroids)\n",
    "\n",
    "            if self.plot_steps:\n",
    "                self.plot()\n",
    "\n",
    "            # Calculate new centroids from the clusters\n",
    "            centroids_old = self.centroids\n",
    "            self.centroids = self._get_centroids(self.clusters)\n",
    "\n",
    "            # check if clusters have changed\n",
    "            if self._is_converged(centroids_old, self.centroids):\n",
    "                break\n",
    "\n",
    "            if self.plot_steps:\n",
    "                self.plot()\n",
    "\n",
    "        # Classify samples as the index of their clusters\n",
    "        return self._get_cluster_labels(self.clusters)\n",
    "\n",
    "    def _get_cluster_labels(self, clusters):\n",
    "        # each sample will get the label of the cluster it was assigned to\n",
    "        labels = np.empty(self.n_samples)\n",
    "\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            for sample_index in cluster:\n",
    "                labels[sample_index] = cluster_idx\n",
    "        return labels\n",
    "\n",
    "    def _create_clusters(self, centroids):\n",
    "        # Assign the samples to the closest centroids to create clusters\n",
    "        clusters = [[] for _ in range(self.K)]\n",
    "        for idx, sample in enumerate(self.X):\n",
    "            centroid_idx = self._closest_centroid(sample, centroids)\n",
    "            clusters[centroid_idx].append(idx)\n",
    "        return clusters\n",
    "\n",
    "    def _closest_centroid(self, sample, centroids):\n",
    "        # distance of the current sample to each centroid\n",
    "        distances = [euclidean_distance(sample, point) for point in centroids]\n",
    "        closest_index = np.argmin(distances)\n",
    "        return closest_index\n",
    "\n",
    "    def _get_centroids(self, clusters):\n",
    "        # assign mean value of clusters to centroids\n",
    "        centroids = np.zeros((self.K, self.n_features))\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            cluster_mean = np.mean(self.X[cluster], axis=0)\n",
    "            centroids[cluster_idx] = cluster_mean\n",
    "        return centroids\n",
    "\n",
    "    def _is_converged(self, centroids_old, centroids):\n",
    "        # distances between each old and new centroids, fol all centroids\n",
    "        distances = [\n",
    "            euclidean_distance(centroids_old[i], centroids[i]) for i in range(self.K)\n",
    "        ]\n",
    "        return sum(distances) == 0\n",
    "\n",
    "    def plot(self):\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "        for i, index in enumerate(self.clusters):\n",
    "            point = self.X[index].T\n",
    "            ax.scatter(*point)\n",
    "\n",
    "        for point in self.centroids:\n",
    "            ax.scatter(*point, marker=\"x\", color=\"black\", linewidth=2)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# inference\n",
    "        \n",
    "X, y = make_blobs(\n",
    "    centers=3, n_samples=500, n_features=2, shuffle=True, random_state=40\n",
    ")\n",
    "print(X.shape)\n",
    "\n",
    "clusters = len(np.unique(y))\n",
    "print(clusters)\n",
    "\n",
    "k = KMeans(K=clusters, max_iters=150)\n",
    "y_pred = k.predict(X)\n",
    "\n",
    "k.plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82d6603",
   "metadata": {},
   "source": [
    "# 3. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5caf733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 205.62086930288888\n",
      "Accuracy: 0.9415332794289129\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    corr_matrix = np.corrcoef(y_true, y_pred)\n",
    "    corr = corr_matrix[0, 1]\n",
    "    return corr ** 2\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, learning_rate=0.001, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # init parameters\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # gradient descent\n",
    "        for _ in range(self.n_iters):\n",
    "            y_predicted = np.dot(X, self.weights) + self.bias\n",
    "            # compute gradients\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "\n",
    "            # update parameters\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_approximated = np.dot(X, self.weights) + self.bias\n",
    "        return y_approximated\n",
    "\n",
    "\n",
    "# Testing\n",
    "if __name__ == \"__main__\":\n",
    "    # Imports\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import datasets\n",
    "\n",
    "    X, y = datasets.make_regression(\n",
    "        n_samples=100, n_features=1, noise=20\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2\n",
    "    )\n",
    "\n",
    "    regressor = LinearRegression(learning_rate=0.01, n_iters=1000)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    predictions = regressor.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    print(\"MSE:\", mse)\n",
    "    accu = r2_score(y_test, predictions)\n",
    "    print(\"Accuracy:\", accu)\n",
    "\n",
    "    y_pred_line = regressor.predict(X)\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    m1 = plt.scatter(X_train, y_train)\n",
    "    m2 = plt.scatter(X_test, y_test)\n",
    "    plt.plot(X, y_pred_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab76ac3",
   "metadata": {},
   "source": [
    "# 4. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41d7ce35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes classification accuracy 0.965\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class NaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self._classes = np.unique(y)\n",
    "        n_classes = len(self._classes)\n",
    "\n",
    "        # calculate mean, var, and prior for each class\n",
    "        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._priors = np.zeros(n_classes, dtype=np.float64)\n",
    "\n",
    "        for idx, c in enumerate(self._classes):\n",
    "            X_c = X[y == c]\n",
    "            self._mean[idx, :] = X_c.mean(axis=0)\n",
    "            self._var[idx, :] = X_c.var(axis=0)\n",
    "            self._priors[idx] = X_c.shape[0] / float(n_samples)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        posteriors = []\n",
    "\n",
    "        # calculate posterior probability for each class\n",
    "        for idx, c in enumerate(self._classes):\n",
    "            prior = np.log(self._priors[idx])\n",
    "            posterior = np.sum(np.log(self._pdf(idx, x)))\n",
    "            posterior = prior + posterior\n",
    "            posteriors.append(posterior)\n",
    "\n",
    "        # return class with highest posterior probability\n",
    "        return self._classes[np.argmax(posteriors)]\n",
    "\n",
    "    def _pdf(self, class_idx, x):\n",
    "        mean = self._mean[class_idx]\n",
    "        var = self._var[class_idx]\n",
    "        numerator = np.exp(-((x - mean) ** 2) / (2 * var))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        return numerator / denominator\n",
    "\n",
    "\n",
    "# Testing\n",
    "if __name__ == \"__main__\":\n",
    "    # Imports\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import datasets\n",
    "\n",
    "    def accuracy(y_true, y_pred):\n",
    "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "        return accuracy\n",
    "\n",
    "    X, y = datasets.make_classification(\n",
    "        n_samples=1000, n_features=10, n_classes=2, random_state=123\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=123\n",
    "    )\n",
    "\n",
    "    nb = NaiveBayes()\n",
    "    nb.fit(X_train, y_train)\n",
    "    predictions = nb.predict(X_test)\n",
    "\n",
    "    print(\"Naive Bayes classification accuracy\", accuracy(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175e322e",
   "metadata": {},
   "source": [
    "# 5. Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2209a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " === Gen0=== \n",
      "Score: 5.836887670587429e-07 || Values: (17.118584544365547, 130.6984812635814, 3793.77243468781)\n",
      " === Gen1=== \n",
      "Score: 0.0003648126201525105 || Values: (0.5384364525782435, 26.01559754237708, 35.3263553978864)\n",
      " === Gen2=== \n",
      "Score: 90.48302606572419 || Values: (0.5391426401284523, 9.86065373648158, 0.5387325526295837)\n",
      " === Gen3=== \n",
      "Score: 6522.084582956698 || Values: (0.5389871311891953, 0.5398272318989527, 9.851343932829925)\n",
      " === Gen4=== \n",
      "Score: 162337.53908199424 || Values: (0.5387172092409479, 9.872548503703264, 0.5390200456439791)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Function to optimize close to '0'\n",
    "def fto(x,y,z):\n",
    "    return 45*x**3 + 3*y*z -23 \n",
    "\n",
    "# Check fitness of the current params\n",
    "def fitness(x,y,z):\n",
    "    ans = fto(x,y,z)\n",
    "    if(ans == 0):\n",
    "        return 999999\n",
    "    else:\n",
    "        return abs(1/ans)\n",
    "\n",
    "solutions = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    solutions.append(\n",
    "                    (random.uniform(0,10000),\n",
    "                    random.uniform(0,10000),\n",
    "                    random.uniform(0,10000)))\n",
    "    \n",
    "for i in range(10000):\n",
    "    rankedsolutions = []\n",
    "    for s in solutions:\n",
    "        rankedsolutions.append( (fitness(s[0],s[1],s[2]), s) )\n",
    "    rankedsolutions.sort()\n",
    "    rankedsolutions.reverse()\n",
    "    \n",
    "    print(f\" === Gen{i}=== \")\n",
    "    print(f\"Score: {rankedsolutions[0][0]} || Values: {rankedsolutions[0][1]}\")\n",
    "    \n",
    "    \n",
    "    if(rankedsolutions[0][0] > 9999):\n",
    "        break\n",
    "    \n",
    "    bestsolutions = rankedsolutions[:100]\n",
    "    \n",
    "    \n",
    "    # Crossover\n",
    "    elements = []\n",
    "    for s in bestsolutions:\n",
    "        elements.append(s[1][0])\n",
    "        elements.append(s[1][1])\n",
    "        elements.append(s[1][2])\n",
    "        \n",
    "    \n",
    "    newGen = []\n",
    "    \n",
    "    # Mutation\n",
    "    for _ in range(10000):\n",
    "        e1 = random.choice(elements)*random.uniform(0.999, 1.001)\n",
    "        e2 = random.choice(elements)*random.uniform(0.999, 1.001)\n",
    "        e3 = random.choice(elements)*random.uniform(0.999, 1.001)\n",
    "        \n",
    "        newGen.append((e1,e2,e3))\n",
    "        solutions = newGen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68811819",
   "metadata": {},
   "source": [
    "# 6. Two Layerd Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "923edf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    #( 4 lines of code)\n",
    "    W1 = np.random.randn(n_h, n_x)*0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h)*0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters    \n",
    "\n",
    "\n",
    "# GRADED FUNCTION: linear_forward\n",
    "\n",
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = np.dot(W, A) + b\n",
    "\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache\n",
    "\n",
    "# GRADED FUNCTION: linear_activation_forward\n",
    "\n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python tuple containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "\n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        \n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# GRADED FUNCTION: compute_cost\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function defined by equation (7).\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    # ( 1 lines of code)\n",
    "    cost = - np.sum(np.multiply(Y, np.log(AL)) + np.multiply((1-Y), np.log(1 - AL))) / m\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "\n",
    "    \n",
    "    return cost\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# GRADED FUNCTION: linear_backward\n",
    "\n",
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    ### START CODE HERE ### ( 3 lines of code)\n",
    "    dW = np.dot(dZ, A_prev.T) / m\n",
    "    db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "# GRADED FUNCTION: linear_activation_backward\n",
    "\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        #( 2 lines of code)\n",
    "        # YOUR CODE STARTS HERE\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        #( 2 lines of code)\n",
    "        # YOUR CODE STARTS HERE\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "# GRADED FUNCTION: update_parameters\n",
    "\n",
    "def update_parameters(params, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    params -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    parameters = params.copy()\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    #( 2 lines of code)\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "    return parameters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# GRADED FUNCTION: update_parameters\n",
    "\n",
    "def update_parameters(params, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    params -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    parameters = params.copy()\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    #( 2 lines of code)\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * grads[\"db\" + str(l + 1)]\n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "    return parameters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# GRADED FUNCTION: two_layer_model\n",
    "\n",
    "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a two-layer neural network: LINEAR->RELU->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (n_x, number of examples)\n",
    "    Y -- true \"label\" vector (containing 1 if cat, 0 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- dimensions of the layers (n_x, n_h, n_y)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- If set to True, this will print the cost every 100 iterations \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary containing W1, W2, b1, and b2\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = []                              # to keep track of the cost\n",
    "    m = X.shape[1]                           # number of examples\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    \n",
    "    # Initialize parameters dictionary, by calling one of the functions you'd previously implemented\n",
    "    #( 1 line of code)\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Get W1, b1, W2 and b2 from the dictionary parameters.\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID. Inputs: \"X, W1, b1, W2, b2\". Output: \"A1, cache1, A2, cache2\".\n",
    "        #( 2 lines of code)\n",
    "        A1, cache1 = linear_activation_forward(X, W1, b1, \"relu\")\n",
    "        A2, cache2 = linear_activation_forward(A1, W2, b2, \"sigmoid\")\n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "        # Compute cost\n",
    "        #( 1 line of code)\n",
    "        cost = compute_cost(A2, Y)\n",
    "        \n",
    "        # Initializing backward propagation\n",
    "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
    "        \n",
    "        # Backward propagation. Inputs: \"dA2, cache2, cache1\". Outputs: \"dA1, dW2, db2; also dA0 (not used), dW1, db1\".\n",
    "        #( 2 lines of code)\n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, \"sigmoid\")\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, \"relu\")\n",
    "        \n",
    "        # Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2\n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        \n",
    "        # Update parameters.\n",
    "        #(approx. 1 line of code)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "\n",
    "        # Retrieve W1, b1, W2, b2 from parameters\n",
    "        W1 = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "        \n",
    "        # Print the cost every 100 iterations\n",
    "        if print_cost and i % 100 == 0 or i == num_iterations - 1:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if i % 100 == 0 or i == num_iterations:\n",
    "            costs.append(cost)\n",
    "\n",
    "    return parameters, costs\n",
    "\n",
    "def plot_costs(costs, learning_rate=0.0075):\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d3c8e",
   "metadata": {},
   "source": [
    "# 7. ID3 Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a387f8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/trainplaytennis/PlayTennis.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-16a9dd938cfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;31m#for mathematical calculation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_data_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/trainplaytennis/PlayTennis.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtest_data_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/testplaytennis/PlayTennis.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bilal\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/trainplaytennis/PlayTennis.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd #for manipulating the csv data\n",
    "import numpy as np #for mathematical calculation\n",
    "\n",
    "train_data_m = pd.read_csv(\"../input/trainplaytennis/PlayTennis.csv\")# (14,5)\n",
    "test_data_m = pd.read_csv(\"../input/testplaytennis/PlayTennis.csv\")# (4,5)\n",
    "\n",
    "train_data_m.head()\n",
    "\n",
    "def calc_total_entropy(train_data, label, class_list):\n",
    "    total_row = train_data.shape[0]\n",
    "    total_entr = 0\n",
    "    \n",
    "    for c in class_list:\n",
    "        total_class_count = train_data[train_data[label] == c].shape[0]\n",
    "        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row) \n",
    "        total_entr += total_class_entr\n",
    "    \n",
    "    return total_entr\n",
    "\n",
    "def calc_entropy(feature_value_data, label, class_list):\n",
    "    class_count = feature_value_data.shape[0]\n",
    "    entropy = 0\n",
    "    \n",
    "    for c in class_list:\n",
    "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0]\n",
    "    \n",
    "        entropy_class = 0\n",
    "        if label_class_count != 0:\n",
    "            probability_class = label_class_count/class_count\n",
    "            entropy_class = - probability_class * np.log2(probability_class) \n",
    "        \n",
    "        entropy += entropy_class\n",
    "        \n",
    "    return entropy\n",
    "\n",
    "\n",
    "def calc_info_gain(feature_name, train_data, label, class_list):\n",
    "    feature_value_list = train_data[feature_name].unique()\n",
    "    total_row = train_data.shape[0]\n",
    "    feature_info = 0.0\n",
    "    \n",
    "    for feature_value in feature_value_list:\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value]\n",
    "        feature_value_count = feature_value_data.shape[0]\n",
    "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list)\n",
    "        feature_value_probability = feature_value_count/total_row\n",
    "        feature_info += feature_value_probability * feature_value_entropy\n",
    "        \n",
    "    return calc_total_entropy(train_data, label, class_list) - feature_info\n",
    "\n",
    "\n",
    "\n",
    "def find_most_informative_feature(train_data, label, class_list):\n",
    "    feature_list = train_data.columns.drop(label)\n",
    "    max_info_gain = -1\n",
    "    max_info_feature = None\n",
    "    \n",
    "    for feature in feature_list:  \n",
    "        feature_info_gain = calc_info_gain(feature, train_data, label, class_list)\n",
    "        if max_info_gain < feature_info_gain:\n",
    "            max_info_gain = feature_info_gain\n",
    "            max_info_feature = feature\n",
    "            \n",
    "    return max_info_feature\n",
    "\n",
    "def generate_sub_tree(feature_name, train_data, label, class_list):\n",
    "    feature_value_count_dict = train_data[feature_name].value_counts(sort=False)\n",
    "    tree = {}\n",
    "    \n",
    "    for feature_value, count in feature_value_count_dict.iteritems():\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value]\n",
    "        \n",
    "        assigned_to_node = False\n",
    "        for c in class_list:\n",
    "            class_count = feature_value_data[feature_value_data[label] == c].shape[0]\n",
    "\n",
    "            if class_count == count:\n",
    "                tree[feature_value] = c\n",
    "                train_data = train_data[train_data[feature_name] != feature_value]\n",
    "                assigned_to_node = True\n",
    "        if not assigned_to_node:\n",
    "            tree[feature_value] = \"?\"\n",
    "            \n",
    "    return tree, train_data\n",
    "\n",
    "def make_tree(root, prev_feature_value, train_data, label, class_list):\n",
    "    if train_data.shape[0] != 0:\n",
    "        max_info_feature = find_most_informative_feature(train_data, label, class_list)\n",
    "        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list)\n",
    "        next_root = None\n",
    "        \n",
    "        if prev_feature_value != None:\n",
    "            root[prev_feature_value] = dict()\n",
    "            root[prev_feature_value][max_info_feature] = tree\n",
    "            next_root = root[prev_feature_value][max_info_feature]\n",
    "        else:\n",
    "            root[max_info_feature] = tree\n",
    "            next_root = root[max_info_feature]\n",
    "        \n",
    "        for node, branch in list(next_root.items()):\n",
    "            if branch == \"?\":\n",
    "                feature_value_data = train_data[train_data[max_info_feature] == node]\n",
    "                make_tree(next_root, node, feature_value_data, label, class_list)\n",
    "                \n",
    "    \n",
    "def id3(train_data_m, label):\n",
    "    train_data = train_data_m.copy()\n",
    "    tree = {}\n",
    "    class_list = train_data[label].unique()\n",
    "    make_tree(tree, None, train_data_m, label, class_list)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "def predict(tree, instance):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    else:\n",
    "        root_node = next(iter(tree))\n",
    "        feature_value = instance[root_node]\n",
    "        if feature_value in tree[root_node]:\n",
    "            return predict(tree[root_node][feature_value], instance)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "def evaluate(tree, test_data_m, label):\n",
    "    correct_preditct = 0\n",
    "    wrong_preditct = 0\n",
    "    for index, row in test_data_m.iterrows():\n",
    "        result = predict(tree, test_data_m.iloc[index])\n",
    "        if result == test_data_m[label].iloc[index]:\n",
    "            correct_preditct += 1\n",
    "        else:\n",
    "            wrong_preditct += 1\n",
    "    accuracy = correct_preditct / (correct_preditct + wrong_preditct)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "tree = id3(train_data_m, 'Play Tennis')\n",
    "tree\n",
    "\n",
    "\n",
    "accuracy = evaluate(tree, test_data_m, 'Play Tennis')\n",
    "print(\"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db56778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
